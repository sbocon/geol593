P2
================
Sam Ocon

Here, I’m loading in all the libraries I will be using for performing
the rate calculation and analysis. Specifically:

-   ape + phytools are used for general wrangling of phylogenetic trees,
    they’re also required by Claddis and paleotree

-   Claddis was used for the stochastic calculation of trait differences
    and automatic evolutionary rate calculations

-   paleotree was used to perform stochastic time scaling and break up
    polytomies

-   foreach and doParallel were used to do multi-core computing! I don’t
    really understand how they work :)

<!-- -->

    library(ape)
    library(paleotree)
    library(Claddis)

    ## Loading required package: phytools

    ## Loading required package: maps

    ## Loading required package: strap

    ## Loading required package: geoscale

    library(phytools)
    library(foreach)
    library(doParallel)

    ## Loading required package: iterators

    ## Loading required package: parallel

## Setting up parallel computing

In this chunk of code, I’m detecting the number of cores my computer
has, then choosing how many I wanted to use to run this code:

Issues: I originally used task manager to check this. My computer has 4
physical cores, but 8 logical cores. I don’t really understand this, so
I just went with the number next to “Cores” in task manager, originally,
then tried 8 after detectCores told me about my other cores!

    #How many cores do I have overall?
    detectCores()

    ## [1] 8

    #Telling the computer how many cores I want to use for parallel computing (I'm leaving some open so I can still do other R processes on my PC)!

    registerDoParallel(cores = 7)

## Importing the data

Yay! We have that set up, so now let’s bring in our tree so we can do
some calculating!

    #Reading my tree in as "xipho"
    xipho <- read.nexus("Data/xipho_tree_updated.tre")

Now I have to read in the table of ages that James and I have worked
together to create so that I can time scale the branches and estimate
when different traits evolved.

    #Time Scaling the tree and breaking up polytomies randomly
    tip.ages <- read.table("Data/Tip_Ages_Ordered.txt", sep = ",", header = TRUE, row.names = 1)

The way that the package Claddis performs, I also have to provide time
bins (which in this case, are just geological stages) and format them as
objects of class “timeBins”.

    #Reading in the time data
    bins <- read.csv("data/dates.csv")

    #I have other, equal length time bins in the csv, so I need to separate them out
    stage <- bins[1:98,2:3]

    #Now I'm formatting the data so that the stages are now just row names, not their own column
    rownames(stage) <- bins[1:98,1]

    #Also, renaming the columns (first appearance date and last appearance date) so that Claddis knows how to read them
    colnames(stage) <- c("fad","lad")

    #You can only make a "matrix" class object into a timeBin, so here I am converting it
    stage <- data.matrix(stage)

    #then just changing the class to a timeBin
    class(stage)<-"timeBins"

    #Did it work??
    is.timeBins(stage)

    ## [1] TRUE

Unhelpfully, paleotree uses another weird data format, so I had to
adjust my first appearance dates and last appearance dates to work with
it.

    #Make a duplicate data frame so I still have my original
    ages2 <- tip.ages

    #Paleotree needs two sets of dates, but I don't have two estimates, so I just am duplicating them and adding them as two more columns
    ages2[,3:4] <- cbind(tip.ages[,1:2])

    #Make it a data frame
    ages2 <- data.frame(ages2)

    #Rename the columns so they work with paleotree
    colnames(ages2) <- c("start_time", "end_time", "start_time", "end_time")

    #convert them to the class/format that paleotree wants EXCEPT
    ages2 <- fourDate2timeList(ages2)


    #Paleotree has updated some functions but not others, so I still have to fix the output a little bit
    ages2[[1]] <- data.frame(ages2[[1]])


    ages2[[2]] <- data.frame(ages2[[2]])

    #Finally, now I just need to change the row names to match the animal they match up with
    rownames(ages2[[2]]) <- rownames(tip.ages)

Now, I can finally break up polytomies and time scale the trees
randomly. Since this process is stochastic, I am going to run it 500
times. I am using the ’mbl" or minimum branch length method, which means
that it is not allowed to make any branches shorter than the length of
time I specify (vartime, in this case, 1 million years); this prevents
it from generating more polytomies. The argument randres tells the
function whether it should resolve polytomies randomly or not (which I
want). add.term just scales the branches to represent the latest
appearance data of the taxa, not the first, which is helpful when we’re
dealing with extant data. Finally, I chose not to plot, because there
are 500 trees and I don’t think I’m going to look at all of those plots
individually.

    #Time scaling the trees and saving them as "xipho trees"
    xiphoTrees <- bin_timePaleoPhy(tree=xipho,timeList=ages2,type="mbl",
                     vartime=1,randres=TRUE,add.term=TRUE,ntrees=500,plot=FALSE)

Okay, now I need to read in my discrete character matrix, which is
basically a checklist of traits that the organisms have and exactly what
state they’re in - so we can figure out how their shapes are changing
through time.

    #Reading in my matrix!
    clad.matrix <- Claddis::read_nexus_matrix("Data/Xiph_Matrix_Claddis.nex")

Finally, performing the analysis!!

    #I wanna know how long this takes, so I'm saving my system time at the start of the analysis
    start_time <- Sys.time()

    #now, I'm telling my computer to store the results of each of the repetitions to a list called "rate.calculations"
    #This loop syntax is special, it's only used for parallel computing, so I had to also specify which packages to run on the other cores.

    #This is exploratory, so I'm telling it to create a rate for every single branch and every single node for every single generated tree.

    #I'm not running the rate per time bin, as this would take 500 more repetitions per each tree, which would be insanely time consuming.

    #I'm making sure that the trait changes are shuffled along branches (change_times=random), and that I will test my results using a likelihood ratio test, where I'm looking for an alpha of <0.01. I'm using otherwise default settings!

    rate.calculations <- foreach(i=1:500, .packages="Claddis") %dopar%{
      # Run rate analysis:
      tree.out <- test_rates(
        time_tree = xiphoTrees[[i]], 
        cladistic_matrix = clad.matrix, 
        time_bins = stage, 
        branch_partitions =
          lapply(X = as.list(x = 1:nrow(xiphoTrees[[i]]$edge)),as.list),
        character_partitions = NULL, 
        clade_partitions =
          lapply(X = as.list(x = ape::Ntip(phy = xiphoTrees[[i]]) + (2:Nnode(xiphoTrees[[i]]))),as.list),
        time_partitions = NULL, 
        change_times = "random", 
        test_type="lrt",
        alpha = 0.01, 
        polymorphism_state = "missing", 
        uncertainty_state = "missing",
        inapplicable_state = "missing", 
        time_binning_approach = "lloyd")
      
    }

    #Now I want it to save the time on my system when this is over
    end_time <- Sys.time()

    #Subtract the two to figure out how long this took!
    end_time - start_time

    ## Time difference of 1.080775 days

Wow, that was a LONG TIME.

Let’s save our data so we don’t have to do this again

    save(rate.calculations, file="Data/RateCalculations_MD.RData")

[Next](https://sbocon.github.io/geol593/P3)
